{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6823b07b-c3a7-4c1e-b3c7-5c31668da256",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#!pip install fsspec==2023.9.2\n",
    "!pip install -q transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0687a5a0-744a-4c86-a0c6-36c15cfded73",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name: transformers\n",
      "Version: 4.36.2\n",
      "Summary: State-of-the-art Machine Learning for JAX, PyTorch and TensorFlow\n",
      "Home-page: https://github.com/huggingface/transformers\n",
      "Author: The Hugging Face team (past and future) with the help of all our contributors (https://github.com/huggingface/transformers/graphs/contributors)\n",
      "Author-email: transformers@huggingface.co\n",
      "License: Apache 2.0 License\n",
      "Location: /opt/conda/lib/python3.10/site-packages\n",
      "Requires: filelock, huggingface-hub, numpy, packaging, pyyaml, regex, requests, safetensors, tokenizers, tqdm\n",
      "Required-by: \n"
     ]
    }
   ],
   "source": [
    "!pip show transformers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89c9e517-70fd-499c-8e23-9de04305f05f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|===========================================================================|\n",
      "|                  PyTorch CUDA memory summary, device ID 0                 |\n",
      "|---------------------------------------------------------------------------|\n",
      "|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n",
      "|===========================================================================|\n",
      "|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocated memory      |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active memory         |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved memory   |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable memory |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from large pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|       from small pool |       0 B  |       0 B  |       0 B  |       0 B  |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Allocations           |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Active allocs         |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| GPU reserved segments |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Non-releasable allocs |       0    |       0    |       0    |       0    |\n",
      "|       from large pool |       0    |       0    |       0    |       0    |\n",
      "|       from small pool |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize allocations  |       0    |       0    |       0    |       0    |\n",
      "|---------------------------------------------------------------------------|\n",
      "| Oversize GPU segments |       0    |       0    |       0    |       0    |\n",
      "|===========================================================================|\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Call torch.cuda.memory_summary() to print the memory summary\n",
    "print(torch.cuda.memory_summary(device=None, abbreviated=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49c8977a-814a-40e4-be9e-83b3395281d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import gc\n",
    "torch.cuda.empty_cache()\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f108252-19bd-44fd-b812-56a2d581025d",
   "metadata": {},
   "source": [
    "### Data preparation\n",
    "- collating data\n",
    "- balancing data\n",
    "- text preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e19c4a03-f11e-4250-9b2c-90e749956f45",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(r'gs://sentiment_response/pjs_all.csv')\n",
    "\n",
    "df['nps'] = df['nps'].replace('10 (Extremely likely)',10)\n",
    "df['nps'] = df['nps'].replace('0 (Not at all likely)',0)\n",
    "df['nps'] = df['nps'].astype(int)\n",
    "\n",
    "#target variable will nps split into demoters, passives and promoters\n",
    "df['nps_group'] = np.where(df['nps'] >= 9,1,\n",
    "                  np.where(df['nps'] <= 6,0,2))\n",
    "\n",
    "df = df[df['nps_group'].isin([0,1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "12f8f8b3-e005-45c5-9f87-beff607c610d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nps_group\n",
       "0     53460\n",
       "1    127693\n",
       "Name: nps, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#df.info()\n",
    "\n",
    "gb = df.groupby('nps_group')['nps'].count()\n",
    "gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "9aeceed5-aa7a-4143-899c-347dd15ccc4e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nps_group\n",
       "0    350\n",
       "1    350\n",
       "Name: nps, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_rows = 350\n",
    "\n",
    "df1 = df[df['nps_group'] == 0].head(max_rows)\n",
    "df2 = df[df['nps_group'] == 1].head(max_rows)\n",
    "\n",
    "\n",
    "df = pd.concat([df1,df2], axis = 0)\n",
    "\n",
    "gb = df.groupby('nps_group')['nps'].count()\n",
    "gb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bf183303-4733-4098-babb-fa54370a6e05",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def text_preprocessing(text):\n",
    "    \"\"\"\n",
    "    - Remove entity mentions (eg. '@united')\n",
    "    - Correct errors (eg. '&amp;' to '&')\n",
    "    @param    text (str): a string to be processed.\n",
    "    @return   text (Str): the processed string.\n",
    "    \"\"\"\n",
    "    # Remove '@name'\n",
    "    text = re.sub(r'(@.*?)[\\s]', ' ', text)\n",
    "\n",
    "    # Replace '&amp;' with '&'\n",
    "    text = re.sub(r'&amp;', '&', text)\n",
    "\n",
    "    # Remove trailing whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "df['response'] = df['response'].apply(lambda x: text_preprocessing(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c0273b80-4ca7-40d3-89d8-96d5976eeb11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['response'],df['nps_group'], test_size = 0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4f9280f-5ae3-4ded-9380-bb37f76a91ed",
   "metadata": {},
   "source": [
    "### Pre-processing for DeBERTa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f63d3649-be49-48af-be27-1fc505190b2a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import DebertaTokenizer, DebertaModel\n",
    "import torch\n",
    "\n",
    "tokenizer = DebertaTokenizer.from_pretrained('microsoft/deberta-base', do_lower_case=True)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "def preprocessing_for_deberta(data):\n",
    "    \"\"\"Perform required preprocessing steps for pretrained DeBERTa.\n",
    "    @param    data (list): List of texts to be processed.\n",
    "    @return   input_ids (torch.Tensor): Tensor of token ids to be fed to a model.\n",
    "    @return   attention_masks (torch.Tensor): Tensor of indices specifying which\n",
    "                  tokens should be attended to by the model.\n",
    "    \"\"\"\n",
    "    # Create empty lists to store outputs\n",
    "    input_ids = []\n",
    "    attention_masks = []\n",
    "\n",
    "    # For every sentence...\n",
    "    for sent in data:\n",
    "        # `encode_plus` will:\n",
    "        #    (1) Tokenize the sentence\n",
    "        #    (2) Add the `[CLS]` and `[SEP]` token to the start and end\n",
    "        #    (3) Truncate/Pad sentence to max length\n",
    "        #    (4) Map tokens to their IDs\n",
    "        #    (5) Create attention mask\n",
    "        #    (6) Return a dictionary of outputs\n",
    "        encoded_sent = tokenizer.encode_plus(\n",
    "            text=sent,                      # Tokenize sentence\n",
    "            add_special_tokens=True,        # Add `[CLS]` and `[SEP]`\n",
    "            max_length=MAX_LEN,             # Max length to truncate/pad\n",
    "            pad_to_max_length=True,         # Pad sentence to max length\n",
    "            return_attention_mask=True      # Return attention mask\n",
    "        )\n",
    "\n",
    "        # Add the outputs to the lists\n",
    "        input_ids.append(encoded_sent.get('input_ids'))\n",
    "        attention_masks.append(encoded_sent.get('attention_mask'))\n",
    "\n",
    "    # Convert lists to tensors\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_masks = torch.tensor(attention_masks)\n",
    "\n",
    "    return input_ids, attention_masks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9050cec8-1494-4583-82a2-95da80b3605e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max length:  490\n"
     ]
    }
   ],
   "source": [
    "#need to specify the maximum string length from responses\n",
    "responses = df['response'].to_numpy()\n",
    "# Encode our concatenated data\n",
    "encoded_response = [tokenizer.encode(sent, add_special_tokens=True) for sent in responses]\n",
    "\n",
    "# Find the maximum length\n",
    "max_len = max([len(sent) for sent in encoded_response])\n",
    "print('Max length: ', max_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "451f24ce-03eb-4222-a8f9-cddccf73f9ec",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizing data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/tokenization_utils_base.py:2618: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Specify `MAX_LEN`\n",
    "MAX_LEN = 500\n",
    "\n",
    "# # Print sentence 0 and its encoded token ids\n",
    "# token_ids = list(preprocessing_for_bert([X_train[0]])[0].squeeze().numpy())\n",
    "# print('Original: ', X_train[0])\n",
    "# print('Token IDs: ', token_ids)\n",
    "\n",
    "# Run function `preprocessing_for_bert` on the train set and the validation set\n",
    "print('Tokenizing data...')\n",
    "train_inputs, train_masks = preprocessing_for_deberta(X_train)\n",
    "val_inputs, val_masks = preprocessing_for_deberta(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "dabf0e39-d5ad-4c33-93f2-565ea914afed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "\n",
    "# Convert other data types to torch.Tensor\n",
    "train_labels = torch.tensor(y_train.to_numpy())\n",
    "val_labels = torch.tensor(y_test.to_numpy())\n",
    "\n",
    "# For fine-tuning BERT, the authors recommend a batch size of 16 or 32.\n",
    "batch_size = 8\n",
    "\n",
    "# Create the DataLoader for our training set\n",
    "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
    "train_sampler = RandomSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n",
    "# Create the DataLoader for our validation set\n",
    "val_data = TensorDataset(val_inputs, val_masks, val_labels)\n",
    "val_sampler = SequentialSampler(val_data)\n",
    "val_dataloader = DataLoader(val_data, sampler=val_sampler, batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cc32e134-1f0b-47a4-afe6-652c2060137e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import DebertaModel, DebertaTokenizer\n",
    "\n",
    "class DebertaClassifier(nn.Module):\n",
    "    \"\"\"DeBERTa Model for Classification Tasks.\n",
    "    \"\"\"\n",
    "    def __init__(self, freeze_deberta=False):\n",
    "        \"\"\"\n",
    "        @param    deberta: a DebertaModel object\n",
    "        @param    classifier: a torch.nn.Module classifier\n",
    "        @param    freeze_deberta (bool): Set `False` to fine-tune the DeBERTa model\n",
    "        \"\"\"\n",
    "        super(DebertaClassifier, self).__init__()\n",
    "        # Specify hidden size of DeBERTa, hidden size of our classifier, and number of labels\n",
    "        D_in, H, D_out = 768, 30, 2\n",
    "\n",
    "        # Instantiate DeBERTa model\n",
    "        self.deberta = DebertaModel.from_pretrained('microsoft/deberta-base')\n",
    "\n",
    "        # Instantiate a one-layer feed-forward classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(D_in, H),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.2),\n",
    "            nn.Linear(H, D_out)\n",
    "        )\n",
    "\n",
    "        # Freeze the DeBERTa model\n",
    "        if freeze_deberta:\n",
    "            for param in self.deberta.parameters():\n",
    "                param.requires_grad = False\n",
    "\n",
    "    def forward(self, input_ids, attention_mask):\n",
    "        \"\"\"\n",
    "        Feed input to DeBERTa and the classifier to compute logits.\n",
    "        @param    input_ids (torch.Tensor): an input tensor with shape (batch_size,\n",
    "                      max_length)\n",
    "        @param    attention_mask (torch.Tensor): a tensor that holds attention mask\n",
    "                      information with shape (batch_size, max_length)\n",
    "        @return   logits (torch.Tensor): an output tensor with shape (batch_size,\n",
    "                      num_labels)\n",
    "        \"\"\"\n",
    "        # Feed input to DeBERTa\n",
    "        outputs = self.deberta(input_ids=input_ids,\n",
    "                               attention_mask=attention_mask)\n",
    "\n",
    "        # Extract the last hidden state of the token `[CLS]` for the classification task\n",
    "        last_hidden_state_cls = outputs.last_hidden_state[:, 0, :]\n",
    "\n",
    "        # Feed input to classifier to compute logits\n",
    "        logits = self.classifier(last_hidden_state_cls)\n",
    "\n",
    "        return logits\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7a205b0a-b786-493f-bd3b-327c3ba3050e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_steps: 17589, so 5863 per epoch\n"
     ]
    }
   ],
   "source": [
    "total_steps = len(train_dataloader) * 3\n",
    "\n",
    "print(f'Total_steps: {total_steps}, so {len(train_dataloader)} per epoch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f260bc53-2cc5-4454-a83f-9949640ece0a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.optim import AdamW\n",
    "def initialize_model(epochs=2):\n",
    "    \"\"\"Initialize the Bert Classifier, the optimizer and the learning rate scheduler.\n",
    "    \"\"\"\n",
    "    # Instantiate Bert Classifier\n",
    "    deberta_classifier = DebertaClassifier()\n",
    "\n",
    "    # Tell PyTorch to run the model on CPU\n",
    "    deberta_classifier.to(device)\n",
    "\n",
    "    # Create the optimizer\n",
    "    optimizer = AdamW(deberta_classifier.parameters(),\n",
    "                      lr=5e-5,    # Default learning rate\n",
    "                      eps=1e-8    # Default epsilon value\n",
    "                      )\n",
    "\n",
    "    # Total number of training steps\n",
    "    total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "    print(f'Total_steps: {total_steps}')\n",
    "\n",
    "    # Set up the learning rate scheduler\n",
    "    scheduler = get_linear_schedule_with_warmup(optimizer,\n",
    "                                                num_warmup_steps=0.1*total_steps, # Default value\n",
    "                                                num_training_steps=total_steps)\n",
    "    return deberta_classifier, optimizer, scheduler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8bd72499-5ad3-4140-b32a-52a848ea8836",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import time\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "\n",
    "# Specify loss function\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def set_seed(seed_value=42):\n",
    "    \"\"\"Set seed for reproducibility.\n",
    "    \"\"\"\n",
    "    random.seed(seed_value)\n",
    "    np.random.seed(seed_value)\n",
    "    torch.manual_seed(seed_value)\n",
    "    torch.cuda.manual_seed_all(seed_value)\n",
    "\n",
    "def train(model, train_dataloader, val_dataloader=val_dataloader, epochs=2, evaluation=True):\n",
    "    \"\"\"Train the BertClassifier model.\n",
    "    \"\"\"\n",
    "    # Start training loop\n",
    "    print(\"Start training...\\n\")\n",
    "    train_loss_list = []\n",
    "    train_accuracy_list = []\n",
    "    val_loss_list = []\n",
    "    val_acc_list = []\n",
    "    batch_list = []\n",
    "    epoch_list = []\n",
    "    epoch_n = -1\n",
    "    for epoch_i in range(epochs):\n",
    "        # =======================================\n",
    "        #               Training\n",
    "        # =======================================\n",
    "        # Print the header of the result table\n",
    "        print(f\"{'Epoch':^7} | {'Batch':^7} | {'Train Loss':^12} | {'Train Accuracy':^12}| {'Val Loss':^10} | {'Val Acc':^9} | {'f1_score':^9} | {'Elapsed':^9}\")\n",
    "        print(\"-\"*70)\n",
    "\n",
    "        # Measure the elapsed time of each epoch\n",
    "        t0_epoch, t0_batch = time.time(), time.time()\n",
    "\n",
    "        # Reset tracking variables at the beginning of each epoch\n",
    "        total_loss, batch_loss, batch_counts = 0, 0, 0\n",
    "\n",
    "        # Put the model into the training mode\n",
    "        model.train()\n",
    "\n",
    "        # For each batch of training data...\n",
    "        for step, batch in enumerate(train_dataloader):\n",
    "            batch_counts +=1\n",
    "            # Load batch to GPU\n",
    "            b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "            # Zero out any previously calculated gradients\n",
    "            model.zero_grad()\n",
    "\n",
    "            # Perform a forward pass. This will return logits.\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "            preds = torch.argmax(logits, dim=1).flatten()\n",
    "            train_accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "\n",
    "            # Compute loss and accumulate the loss values\n",
    "            loss = loss_fn(logits, b_labels)\n",
    "            batch_loss += loss.item()\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            # Perform a backward pass to calculate gradients\n",
    "            loss.backward()\n",
    "\n",
    "            # Clip the norm of the gradients to 1.0 to prevent \"exploding gradients\"\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "\n",
    "            # Update parameters and the learning rate\n",
    "            optimizer.step()\n",
    "            scheduler.step()\n",
    "\n",
    "            # Print the loss values and time elapsed for every 20 batches\n",
    "            if (step % 2931 == 0 and step != 0) or (step == len(train_dataloader) - 1): #(epoch_n != epoch_i) and (step != 0):\n",
    "                # Calculate time elapsed for 20 batches\n",
    "                time_elapsed = time.time() - t0_batch\n",
    "\n",
    "                # Print training results\n",
    "                #print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {'-':^10} | {'-':^9} | {time_elapsed:^9.2f}\")\n",
    "\n",
    "                # Perform validation every n batches\n",
    "                if evaluation:\n",
    "                    # Calculate validation loss and accuracy\n",
    "                    val_loss, val_accuracy, f1_score = evaluate(model, val_dataloader)\n",
    "\n",
    "                    # Print validation results\n",
    "                    print(f\"{epoch_i + 1:^7} | {step:^7} | {batch_loss / batch_counts:^12.6f} | {train_accuracy:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {f1_score:^9.2f} | {'-':^9}\")\n",
    "                    train_loss_list.append(batch_loss / batch_counts)\n",
    "                    train_accuracy_list.append(train_accuracy)\n",
    "                    val_loss_list.append(val_loss)\n",
    "                    val_acc_list.append(val_accuracy)\n",
    "                    batch_list.append(step)\n",
    "                    epoch_list.append(epoch_i)\n",
    "\n",
    "                # Reset batch tracking variables\n",
    "                batch_loss, batch_counts = 0, 0\n",
    "                t0_batch = time.time()\n",
    "\n",
    "            epoch_n = epoch_i\n",
    "\n",
    "        # Calculate the average loss over the entire training data\n",
    "        avg_train_loss = total_loss / len(train_dataloader)\n",
    "\n",
    "        print(\"-\"*70)\n",
    "        # =======================================\n",
    "        #               Evaluation\n",
    "        # =======================================\n",
    "        if evaluation == True:\n",
    "            # After the completion of each training epoch, measure the model's performance\n",
    "            # on our validation set.\n",
    "            val_loss, val_accuracy, f1_score = evaluate(model, val_dataloader)\n",
    "\n",
    "            # Print performance over the entire training data\n",
    "            time_elapsed = time.time() - t0_epoch\n",
    "\n",
    "            print(f\"{epoch_i + 1:^7} | {'-':^7} | {avg_train_loss:^12.6f} | {train_accuracy:^12.6f} | {val_loss:^10.6f} | {val_accuracy:^9.2f} | {f1_score:^9.2f} | {time_elapsed:^9.2f}\")\n",
    "            print(\"-\"*70)\n",
    "        print(\"\\n\")\n",
    "    loss_info = pd.DataFrame(list(zip( epoch_list, batch_list, train_loss_list, val_loss_list, val_acc_list )), columns = ['epoch','batch', 'train loss', 'val loss','val accuracy'])\n",
    "    print(\"Training complete!\")\n",
    "\n",
    "    return loss_info\n",
    "\n",
    "\n",
    "\n",
    "# def evaluate(model, val_dataloader):\n",
    "#     \"\"\"After the completion of each training epoch, measure the model's performance\n",
    "#     on our validation set.\n",
    "#     \"\"\"\n",
    "#     # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "#     # the test time.\n",
    "#     model.eval()\n",
    "\n",
    "#     # Tracking variables\n",
    "#     val_accuracy = []\n",
    "#     val_loss = []\n",
    "\n",
    "#     # For each batch in our validation set...\n",
    "#     for batch in val_dataloader:\n",
    "#         # Load batch to GPU\n",
    "#         b_input_ids, b_attn_mask, b_labels = tuple(t.to(device) for t in batch)\n",
    "\n",
    "#         # Compute logits\n",
    "#         with torch.no_grad():\n",
    "#             logits = model(b_input_ids, b_attn_mask)\n",
    "\n",
    "#         # Compute loss\n",
    "#         loss = loss_fn(logits, b_labels)\n",
    "#         val_loss.append(loss.item())\n",
    "\n",
    "#         # Get the predictions\n",
    "#         preds = torch.argmax(logits, dim=1).flatten()\n",
    "\n",
    "#         # Calculate the accuracy rate\n",
    "#         accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "#         val_accuracy.append(accuracy)\n",
    "\n",
    "#     # Compute the average accuracy and loss over the validation set.\n",
    "#     val_loss = np.mean(val_loss)\n",
    "#     val_accuracy = np.mean(val_accuracy)\n",
    "\n",
    "#     return val_loss, val_accuracy\n",
    "\n",
    "\n",
    "def evaluate(model, val_dataloader):\n",
    "    model.eval()\n",
    "\n",
    "    val_accuracy = []\n",
    "    val_loss = []\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in val_dataloader:\n",
    "            b_input_ids, b_attn_mask, b_labels = (t.to(device) for t in batch)\n",
    "\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "            loss = loss_fn(logits, b_labels)\n",
    "            val_loss.append(loss.item())\n",
    "\n",
    "            preds = torch.argmax(logits, dim=1).flatten()\n",
    "            accuracy = (preds == b_labels).cpu().numpy().mean() * 100\n",
    "            val_accuracy.append(accuracy)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(b_labels.cpu().numpy())\n",
    "\n",
    "    val_loss = np.mean(val_loss)\n",
    "    val_accuracy = np.mean(val_accuracy)\n",
    "\n",
    "    # Calculate weighted F1 score\n",
    "    class_weights = compute_class_weight('balanced', classes =  np.unique(all_labels), y = all_labels)\n",
    "    f1 = f1_score(all_labels, all_preds, average='macro', labels=np.unique(all_labels))\n",
    "\n",
    "    return val_loss, val_accuracy, f1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "167e156a-f8e5-49ae-ad69-8c2622eb74af",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_steps: 11726\n",
      "Start training...\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Accuracy|  Val Loss  |  Val Acc  | f1_score  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   1    |  2931   |   0.248138   |  100.000000  |  0.183732  |   95.32   |   0.95    |     -    \n",
      "   1    |  5862   |   0.209904   |  75.000000   |  0.207889  |   94.16   |   0.94    |     -    \n",
      "----------------------------------------------------------------------\n",
      "   1    |    -    |   0.229024   |  75.000000   |  0.207889  |   94.16   |   0.94    | 10024.52 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      " Epoch  |  Batch  |  Train Loss  | Train Accuracy|  Val Loss  |  Val Acc  | f1_score  |  Elapsed \n",
      "----------------------------------------------------------------------\n",
      "   2    |  2931   |   0.167128   |  87.500000   |  0.160575  |   96.52   |   0.97    |     -    \n",
      "   2    |  5862   |   0.115243   |  100.000000  |  0.129192  |   96.77   |   0.97    |     -    \n",
      "----------------------------------------------------------------------\n",
      "   2    |    -    |   0.141190   |  100.000000  |  0.129192  |   96.77   |   0.97    | 10020.20 \n",
      "----------------------------------------------------------------------\n",
      "\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "set_seed(42)    # Set seed for reproducibility\n",
    "DebertaClassifier, optimizer, scheduler = initialize_model(epochs=2)\n",
    "loss_info = train(DebertaClassifier, train_dataloader, val_dataloader, epochs=2, evaluation=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8a91884f-ca5d-4eb4-a763-95e72030feb1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def bert_predict(model, test_dataloader):\n",
    "    \"\"\"Perform a forward pass on the trained BERT model to predict probabilities\n",
    "    on the test set.\n",
    "    \"\"\"\n",
    "    # Put the model into the evaluation mode. The dropout layers are disabled during\n",
    "    # the test time.\n",
    "    model.eval()\n",
    "\n",
    "    all_logits = []\n",
    "\n",
    "    # For each batch in our test set...\n",
    "    for batch in test_dataloader:\n",
    "        # Load batch to GPU\n",
    "        b_input_ids, b_attn_mask = tuple(t.to(device) for t in batch)[:2]\n",
    "\n",
    "        # Compute logits\n",
    "        with torch.no_grad():\n",
    "            logits = model(b_input_ids, b_attn_mask)\n",
    "        all_logits.append(logits)\n",
    "\n",
    "    # Concatenate logits from each batch\n",
    "    all_logits = torch.cat(all_logits, dim=0)\n",
    "\n",
    "    # Apply softmax to calculate probabilities\n",
    "    probs = F.softmax(all_logits).cpu().numpy()\n",
    "\n",
    "    return probs\n",
    "\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc\n",
    "\n",
    "def evaluate_roc(probs, y_true):\n",
    "    \"\"\"\n",
    "    - Print AUC and accuracy on the test set\n",
    "    - Plot ROC\n",
    "    @params    probs (np.array): an array of predicted probabilities with shape (len(y_true), 2)\n",
    "    @params    y_true (np.array): an array of the true values with shape (len(y_true),)\n",
    "    \"\"\"\n",
    "    # preds = probs[:, 1]\n",
    "    # fpr, tpr, threshold = roc_curve(y_true, preds)\n",
    "    # roc_auc = auc(fpr, tpr)\n",
    "    #print(f'AUC: {roc_auc:.4f}')\n",
    "\n",
    "    # Get accuracy over the test set\n",
    "    accuracy = accuracy_score(y_true, probs)\n",
    "    print(f'Accuracy: {accuracy*100:.2f}%')\n",
    "\n",
    "    # # Plot ROC AUC\n",
    "    # plt.title('Receiver Operating Characteristic')\n",
    "    # plt.plot(fpr, tpr, 'b', label = 'AUC = %0.2f' % roc_auc)\n",
    "    # plt.legend(loc = 'lower right')\n",
    "    # plt.plot([0, 1], [0, 1],'r--')\n",
    "    # plt.xlim([0, 1])\n",
    "    # plt.ylim([0, 1])\n",
    "    # plt.ylabel('True Positive Rate')\n",
    "    # plt.xlabel('False Positive Rate')\n",
    "    # plt.show()\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "410b90e3-e882-4064-9a0d-e531f7fdb7d3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/tmp/ipykernel_20893/378880163.py:29: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  probs = F.softmax(all_logits).cpu().numpy()\n"
     ]
    }
   ],
   "source": [
    "# Compute predicted probabilities on the test set\n",
    "probs = bert_predict(deberta3, val_dataloader)\n",
    "\n",
    "# #converting softmax probabilities to classification\n",
    "# classification = probs.argmax(axis = 1)\n",
    "# # # Evaluate the Bert classifier\n",
    "# evaluate_roc(classification, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b7bc479e-4cda-46f7-b658-ca1c81ec43bc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 98.27%\n"
     ]
    }
   ],
   "source": [
    "#converting softmax probabilities to classification\n",
    "classification = probs.argmax(axis = 1)\n",
    "# # Evaluate the Bert classifier\n",
    "accuracy = evaluate_roc(classification, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "686ca4bb-a17b-4132-a106-25ff3c58e286",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "709     0\n",
       "231     1\n",
       "74      1\n",
       "699     0\n",
       "1308    0\n",
       "       ..\n",
       "1253    0\n",
       "1225    0\n",
       "470     1\n",
       "1300    0\n",
       "395     1\n",
       "Name: nps_group, Length: 231, dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6a0a7171-2143-45c3-ad00-d51f11176a88",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    _|    _|  _|    _|    _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|_|_|_|    _|_|      _|_|_|  _|_|_|_|\n",
      "    _|    _|  _|    _|  _|        _|          _|    _|_|    _|  _|            _|        _|    _|  _|        _|\n",
      "    _|_|_|_|  _|    _|  _|  _|_|  _|  _|_|    _|    _|  _|  _|  _|  _|_|      _|_|_|    _|_|_|_|  _|        _|_|_|\n",
      "    _|    _|  _|    _|  _|    _|  _|    _|    _|    _|    _|_|  _|    _|      _|        _|    _|  _|        _|\n",
      "    _|    _|    _|_|      _|_|_|    _|_|_|  _|_|_|  _|      _|    _|_|_|      _|        _|    _|    _|_|_|  _|_|_|_|\n",
      "\n",
      "    To login, `huggingface_hub` requires a token generated from https://huggingface.co/settings/tokens .\n",
      "Token: Traceback (most recent call last):\n",
      "  File \"/opt/conda/bin/huggingface-cli\", line 8, in <module>\n",
      "    sys.exit(main())\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/commands/huggingface_cli.py\", line 49, in main\n",
      "    service.run()\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/commands/user.py\", line 98, in run\n",
      "    login(token=self.args.token, add_to_git_credential=self.args.add_to_git_credential)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/_login.py\", line 113, in login\n",
      "    interpreter_login(new_session=new_session, write_permission=write_permission)\n",
      "  File \"/opt/conda/lib/python3.10/site-packages/huggingface_hub/_login.py\", line 189, in interpreter_login\n",
      "    token = getpass(\"Token: \")\n",
      "  File \"/opt/conda/lib/python3.10/getpass.py\", line 77, in unix_getpass\n",
      "    passwd = _raw_input(prompt, stream, input=input)\n",
      "  File \"/opt/conda/lib/python3.10/getpass.py\", line 146, in _raw_input\n",
      "    line = input.readline()\n",
      "  File \"/opt/conda/lib/python3.10/codecs.py\", line 319, in decode\n",
      "    def decode(self, input, final=False):\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "#### saving model to checkpoint first\n",
    "!huggingface-cli login"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6081729d-c90a-4d80-a908-e0554407daaa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/transformers/utils/hub.py:821: FutureWarning: The `use_auth_token` argument is deprecated and will be removed in v5 of Transformers. Please use `token` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CommitInfo(commit_url='https://huggingface.co/nxnag/sentiment-transport/commit/09edb32abad0324d05c61cd5d87b7f7e3ee3ae11', commit_message='Upload tokenizer', commit_description='', oid='09edb32abad0324d05c61cd5d87b7f7e3ee3ae11', pr_url=None, pr_revision=None, pr_num=None)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "your_token = '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'\n",
    "tokenizer.push_to_hub(\"sentiment-transport\", use_auth_token=your_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2ed8f294-ee0a-4668-bf7b-373b0073c9ea",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DebertaClassifier' object has no attribute 'push_to_hub'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mDebertaClassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentiment-transport\u001b[39m\u001b[38;5;124m\"\u001b[39m, token\u001b[38;5;241m=\u001b[39myour_token)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1269\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1268\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1269\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DebertaClassifier' object has no attribute 'push_to_hub'"
     ]
    }
   ],
   "source": [
    "DebertaClassifier.push_to_hub(\"sentiment-transport\", token=your_token)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3042d4cb-423d-47d2-ba21-0984cab478fa",
   "metadata": {},
   "source": [
    "## Saving the model and recording its production"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "35540045-8d4c-4b60-9eb2-288fd8a00af1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'surveys-402414'"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "project = !gcloud config get-value project\n",
    "PROJECT_ID = project[0]\n",
    "PROJECT_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "2983912b-c972-4b4f-a9b0-5495550c96c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#saving the model \n",
    "from datetime import datetime\n",
    "REGION = 'europe-west2'\n",
    "EXPERIMENT = '01'\n",
    "SERIES = '01'\n",
    "\n",
    "TIMESTAMP = datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "BUCKET = PROJECT_ID\n",
    "URI = f\"gs://{BUCKET}/{SERIES}/{EXPERIMENT}\"\n",
    "DIR = f\"temp/{EXPERIMENT}\"\n",
    "BLOB = r\"{SERIES}/{EXPERIMENT}/models/{TIMESTAMP}/model/sentiment_classifier.pt\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "cbf98d6e-bb5a-42da-ab36-7945bdf8caa6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FRAMEWORK = 'pytorch'\n",
    "TASK = 'classification'\n",
    "MODEL_TYPE = 'deberta'\n",
    "EXPERIMENT_NAME = f'experiment-{SERIES}-{EXPERIMENT}-{FRAMEWORK}-{TASK}-{MODEL_TYPE}'\n",
    "RUN_NAME = f'run-{TIMESTAMP}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "246f77af-32b2-4ab7-8108-6a963269a4f9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Required packages\n",
    "from google.cloud import aiplatform\n",
    "from google.cloud import storage\n",
    "import json\n",
    "\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "from google.protobuf import json_format\n",
    "from google.protobuf.struct_pb2 import Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c71751f3-74b7-4c21-8dc0-27421ec023d3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9ead1184-e50a-4425-b696-9f7c0703097d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!rm -rf {DIR}\n",
    "!mkdir -p {DIR}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b647b79-ebaf-4c63-9b89-c9845677a702",
   "metadata": {},
   "source": [
    "## Initialising experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b9f19dab-0239-4a89-a260-1a3b9070a38b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "aiplatform.init(experiment = EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "83b99566-10be-4536-a95a-ff646b3a9731",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Associating projects/240414127532/locations/europe-west2/metadataStores/default/contexts/experiment-01-01-pytorch-classification-deberta-run-20240118133149 to Experiment: experiment-01-01-pytorch-classification-deberta\n"
     ]
    }
   ],
   "source": [
    "expRun = aiplatform.ExperimentRun.create(run_name = RUN_NAME, experiment = EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "34ae6e69-3fd5-48d3-82df-89dcd4998546",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#log parameters to the experiment run:\n",
    "expRun.log_params({'experiment': EXPERIMENT, 'series': SERIES, 'project_id': PROJECT_ID})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "cc4ca9ef-ba64-4d37-b36b-57d73b72e932",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "accuracy = '96.77%'\n",
    "expRun.log_metrics({'test_accuracy': accuracy})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e417773-17f3-4ff4-8075-45f7f03e78e1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Saving model for later use "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "de2f2675-63d1-43e1-93e7-fc08138bfa04",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_save_name = 'deberta_classifier.pt'\n",
    "path = F\"{model_save_name}\"\n",
    "torch.save(DebertaClassifier.state_dict(), path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6f86f1c4-ebf0-4fb1-93f9-75c4bc09d309",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Parent directory gs://sentiment_response does not exist.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msave\u001b[49m\u001b[43m(\u001b[49m\u001b[43mDebertaClassifier\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mgs://sentiment_response/bert_sentiment.pt\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:422\u001b[0m, in \u001b[0;36msave\u001b[0;34m(obj, f, pickle_module, pickle_protocol, _use_new_zipfile_serialization)\u001b[0m\n\u001b[1;32m    419\u001b[0m _check_dill_version(pickle_module)\n\u001b[1;32m    421\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _use_new_zipfile_serialization:\n\u001b[0;32m--> 422\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43m_open_zipfile_writer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m opened_zipfile:\n\u001b[1;32m    423\u001b[0m         _save(obj, opened_zipfile, pickle_module, pickle_protocol)\n\u001b[1;32m    424\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:309\u001b[0m, in \u001b[0;36m_open_zipfile_writer\u001b[0;34m(name_or_buffer)\u001b[0m\n\u001b[1;32m    307\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    308\u001b[0m     container \u001b[38;5;241m=\u001b[39m _open_zipfile_writer_buffer\n\u001b[0;32m--> 309\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mcontainer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname_or_buffer\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/serialization.py:287\u001b[0m, in \u001b[0;36m_open_zipfile_writer_file.__init__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m    286\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, name) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 287\u001b[0m     \u001b[38;5;28msuper\u001b[39m(_open_zipfile_writer_file, \u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_C\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPyTorchFileWriter\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Parent directory gs://sentiment_response does not exist."
     ]
    }
   ],
   "source": [
    "torch.save(DebertaClassifier.state_dict(),  'gs://sentiment_response/bert_sentiment.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9a301f37-20fd-49fe-a13f-382c227ca67d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Upload the model to GCS\n",
    "bucket = storage.Client().bucket('sentiment_response')\n",
    "blob = bucket.blob('deberta/deberta_classifier.pt')\n",
    "blob.upload_from_filename('deberta_classifier.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d05448b-a18f-4c01-b9c3-acd4d34e2987",
   "metadata": {},
   "outputs": [],
   "source": [
    "blob = bucket.blob('test2/deberta_classifier.pt')\n",
    "blob.upload_from_filename('deberta_classifier.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "91ff5b42-354b-41b0-aeee-71570dcfe043",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gs://sentiment_response/deberta/deberta_classifier.pt\n"
     ]
    }
   ],
   "source": [
    "!gsutil ls gs://sentiment_response/deberta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "9b32f62b-335a-435d-83af-6fcbd68c08f5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from google.cloud import storage\n",
    "\n",
    "def download_model_weight(bucket_name, source_blob_name, destination_file_path):\n",
    "    \"\"\"Downloads a model weight file from Google Cloud Storage.\"\"\"\n",
    "    storage_client = storage.Client()\n",
    "\n",
    "    bucket = storage_client.bucket(bucket_name)\n",
    "    blob = bucket.blob(source_blob_name)\n",
    "\n",
    "    # Download the model weight file\n",
    "    blob.download_to_filename(destination_file_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    bucket_name = \"sentiment_response\"\n",
    "    source_blob_name = r\"deberta/deberta_classifier.pt\"  # Path to the model weight file in the bucket\n",
    "    destination_file_path = \"model_weights.pt\"  # Local path where you want to save the model weight file\n",
    "\n",
    "    download_model_weight(bucket_name, source_blob_name, destination_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "40b1dcac-bac6-45fa-81e0-94066594ebc0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total_steps: 11726\n"
     ]
    }
   ],
   "source": [
    "deberta3, optimizer, scheduler = initialize_model(epochs=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1983d59d-d93a-4d28-892d-5071a66d7634",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#model_save_name = 'bert_classifier.pt'\n",
    "path = r\"model_weights.pt\"\n",
    "deberta3.load_state_dict(torch.load(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8a8d19be-b873-485e-b30e-cc5431c918d5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: huggingface_hub in /opt/conda/lib/python3.10/site-packages (0.20.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2023.12.1)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (2.31.0)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.66.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (4.8.0)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/conda/lib/python3.10/site-packages (from huggingface_hub) (23.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->huggingface_hub) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install huggingface_hub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7e50cd3c-ef58-483b-b23a-4fde5c7ddd71",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "941e8649496b4e23b2c5f3a65de459ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2475cb6a-d336-4be0-91e4-664485973c9d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.36.2)\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.13.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.20.2)\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.25.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (23.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.12.25)\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.4.1)\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2023.12.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.8.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.6)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.18)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.11.17)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3826b744-db64-4736-b9f5-f6e576149b7c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DebertaClassifier' object has no attribute 'push_to_hub'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m#your_token = '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'\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m \u001b[43mdeberta2\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpush_to_hub\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msentiment-transport\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1269\u001b[0m, in \u001b[0;36mModule.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m modules:\n\u001b[1;32m   1268\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m modules[name]\n\u001b[0;32m-> 1269\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   1270\u001b[0m     \u001b[38;5;28mtype\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DebertaClassifier' object has no attribute 'push_to_hub'"
     ]
    }
   ],
   "source": [
    "#your_token = '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'\n",
    "deberta2.push_to_hub(\"sentiment-transport\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a3e6354f-9d6e-4951-9b3b-6814c91260d8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__main__.DebertaClassifier"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(deberta2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6725f460-b9c4-48ad-a4f3-d46eb8c53cb7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#logging where the model has been saved\n",
    "expRun.log_params({'model.save': r'gs://sentiment_response/deberta/deberta_classifier.pt'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "ea23f9cd-8433-47aa-8d5d-86ebf5543459",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Already in Registry:\n",
      "Loading model as new default version.\n",
      "Creating Model\n",
      "Create Model backing LRO: projects/240414127532/locations/europe-west2/models/model_01_01/operations/3039895113858809856\n",
      "Model created. Resource name: projects/240414127532/locations/europe-west2/models/model_01_01@3\n",
      "To use this Model in another session:\n",
      "model = aiplatform.Model('projects/240414127532/locations/europe-west2/models/model_01_01@3')\n"
     ]
    }
   ],
   "source": [
    "modelmatch = aiplatform.Model.list(filter = f'display_name={SERIES}_{EXPERIMENT} AND labels.series={SERIES} AND labels.experiment={EXPERIMENT}')\n",
    "\n",
    "upload_model = True\n",
    "if modelmatch:\n",
    "    print(\"Model Already in Registry:\")\n",
    "    if RUN_NAME in modelmatch[0].version_aliases:\n",
    "        print(\"This version already loaded, no action taken.\")\n",
    "        upload_model = False\n",
    "        model = aiplatform.Model(model_name = modelmatch[0].resource_name)\n",
    "    else:\n",
    "        print('Loading model as new default version.')\n",
    "        parent_model = modelmatch[0].resource_name\n",
    "\n",
    "else:\n",
    "    print('This is a new model, creating in model registry')\n",
    "    parent_model = ''\n",
    "\n",
    "if upload_model:\n",
    "    model = aiplatform.Model.upload(\n",
    "        display_name = f'{SERIES}_{EXPERIMENT}',\n",
    "        model_id = f'model_{SERIES}_{EXPERIMENT}',\n",
    "        parent_model =  parent_model,\n",
    "        serving_container_image_uri = 'europe-docker.pkg.dev/vertex-ai/training/pytorch-gpu.1-13:latest',\n",
    "        artifact_uri =r'gs://sentiment_response/01/01/models/20231024142940/model',\n",
    "        is_default_version = True,\n",
    "        version_aliases = [RUN_NAME],\n",
    "        version_description = RUN_NAME,\n",
    "        labels = {'series' : f'{SERIES}', 'experiment' : f'{EXPERIMENT}', 'experiment_name' : f'{EXPERIMENT_NAME}', 'run_name' : f'{RUN_NAME}'}        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6c59fc1c-4206-4a7b-a04c-86c43fea5163",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Review the model in the Vertex AI Model Registry:\n",
      "https://console.cloud.google.com/vertex-ai/locations/europe-west2/models/model_01_01?project=surveys-402414\n"
     ]
    }
   ],
   "source": [
    "print(f'Review the model in the Vertex AI Model Registry:\\nhttps://console.cloud.google.com/vertex-ai/locations/{REGION}/models/{model.name}?project={PROJECT_ID}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "7ccb3949-9ab4-4026-9fed-2b7a58de56d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#update model descriptions\n",
    "expRun.log_params({\n",
    "    'model.uri': model.uri,\n",
    "    'model.display_name': model.display_name,\n",
    "    'model.name': model.name,\n",
    "    'model.resource_name': model.resource_name,\n",
    "    'model.version_id': model.version_id,\n",
    "    'model.versioned_resource_name': model.versioned_resource_name\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "91c81a21-fadf-482a-a187-e3ffdd1a2920",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#complete experiment run\n",
    "expRun.update_state(state = aiplatform.gapic.Execution.State.COMPLETE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "9136884b-ecce-4ccd-8aa8-c75fd6588918",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp = aiplatform.Experiment(experiment_name = EXPERIMENT_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e175ebec-925c-446b-8a6f-14c83a2eed48",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment_name</th>\n",
       "      <th>run_name</th>\n",
       "      <th>run_type</th>\n",
       "      <th>state</th>\n",
       "      <th>param.model.save</th>\n",
       "      <th>param.model.versioned_resource_name</th>\n",
       "      <th>param.series</th>\n",
       "      <th>param.model.display_name</th>\n",
       "      <th>param.experiment</th>\n",
       "      <th>param.model.name</th>\n",
       "      <th>param.model.resource_name</th>\n",
       "      <th>param.model.uri</th>\n",
       "      <th>param.model.version_id</th>\n",
       "      <th>param.project_id</th>\n",
       "      <th>metric.test_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>experiment-01-01-pytorch-classification-deberta</td>\n",
       "      <td>run-20240118133149</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>gs://sentiment_response/deberta/deberta_classi...</td>\n",
       "      <td>projects/240414127532/locations/europe-west2/m...</td>\n",
       "      <td>01</td>\n",
       "      <td>01_01</td>\n",
       "      <td>01</td>\n",
       "      <td>model_01_01</td>\n",
       "      <td>projects/240414127532/locations/europe-west2/m...</td>\n",
       "      <td>gs://sentiment_response/01/01/models/202310241...</td>\n",
       "      <td>3</td>\n",
       "      <td>surveys-402414</td>\n",
       "      <td>96.77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>experiment-01-01-pytorch-classification-deberta</td>\n",
       "      <td>run-20240117211743</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>RUNNING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>surveys-402414</td>\n",
       "      <td>96.77%</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>experiment-01-01-pytorch-classification-deberta</td>\n",
       "      <td>run-20231102140225</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>RUNNING</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>surveys-402414</td>\n",
       "      <td>0.86747</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>experiment-01-01-pytorch-classification-deberta</td>\n",
       "      <td>run-20231101142133</td>\n",
       "      <td>system.ExperimentRun</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>gs://sentiment_response/01/01/models/202310241...</td>\n",
       "      <td>projects/240414127532/locations/europe-west2/m...</td>\n",
       "      <td>01</td>\n",
       "      <td>01_01</td>\n",
       "      <td>01</td>\n",
       "      <td>model_01_01</td>\n",
       "      <td>projects/240414127532/locations/europe-west2/m...</td>\n",
       "      <td>gs://absa-classification/01/01/models/20231101...</td>\n",
       "      <td>2</td>\n",
       "      <td>surveys-402414</td>\n",
       "      <td>0.759036</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                   experiment_name            run_name  \\\n",
       "0  experiment-01-01-pytorch-classification-deberta  run-20240118133149   \n",
       "1  experiment-01-01-pytorch-classification-deberta  run-20240117211743   \n",
       "2  experiment-01-01-pytorch-classification-deberta  run-20231102140225   \n",
       "3  experiment-01-01-pytorch-classification-deberta  run-20231101142133   \n",
       "\n",
       "               run_type     state  \\\n",
       "0  system.ExperimentRun  COMPLETE   \n",
       "1  system.ExperimentRun   RUNNING   \n",
       "2  system.ExperimentRun   RUNNING   \n",
       "3  system.ExperimentRun  COMPLETE   \n",
       "\n",
       "                                    param.model.save  \\\n",
       "0  gs://sentiment_response/deberta/deberta_classi...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  gs://sentiment_response/01/01/models/202310241...   \n",
       "\n",
       "                 param.model.versioned_resource_name param.series  \\\n",
       "0  projects/240414127532/locations/europe-west2/m...           01   \n",
       "1                                                NaN           01   \n",
       "2                                                NaN           01   \n",
       "3  projects/240414127532/locations/europe-west2/m...           01   \n",
       "\n",
       "  param.model.display_name param.experiment param.model.name  \\\n",
       "0                    01_01               01      model_01_01   \n",
       "1                      NaN               01              NaN   \n",
       "2                      NaN               01              NaN   \n",
       "3                    01_01               01      model_01_01   \n",
       "\n",
       "                           param.model.resource_name  \\\n",
       "0  projects/240414127532/locations/europe-west2/m...   \n",
       "1                                                NaN   \n",
       "2                                                NaN   \n",
       "3  projects/240414127532/locations/europe-west2/m...   \n",
       "\n",
       "                                     param.model.uri param.model.version_id  \\\n",
       "0  gs://sentiment_response/01/01/models/202310241...                      3   \n",
       "1                                                NaN                    NaN   \n",
       "2                                                NaN                    NaN   \n",
       "3  gs://absa-classification/01/01/models/20231101...                      2   \n",
       "\n",
       "  param.project_id metric.test_accuracy  \n",
       "0   surveys-402414               96.77%  \n",
       "1   surveys-402414               96.77%  \n",
       "2   surveys-402414              0.86747  \n",
       "3   surveys-402414             0.759036  "
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp.get_data_frame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bd69c2c-c208-4679-b81e-b9d04c5f6941",
   "metadata": {},
   "source": [
    "## Now need to have a current version which is managed in the model registry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4f8f42a-dcf8-4789-8540-e866996c9176",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": ".m114",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/:m114"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
